MALWARE DETECTION AND ANALYSIS

A pre-requisite group project to pass the Decision Optimization and Data Analytics course taught by Professor Fabrizio and Professor Manno of the Department of Information Engineering and Computer Science and Mathematics, University of L'Aquila, Italy . The project was carried out by Augustine Oloche Noah (myself), Esther Osikoya and Babatunde Abdullahi Olatunji, MSc Mathematical Engineering students of 2022/2023 academic session.

The dataset contains the dynamic features of 107,888 executables, collected by VirusShare from Nov/2010 to Jul/2014. The features were extracted from the artifacts generated by the executables in the Cukoo Sandbox. The dataset tagged Dynamic Features of VirusShare Executables was obtained from the UCI Library (https://archive.ics.uci.edu/dataset/413/dynamic+features+of+virusshare+executables).

It is a sparse dataset with 482 features (which can be found here https://git.io/vDywd), all integer datatype and 107888 observation in txt format.

Our end result in this project was to analyse the dataset and create supervised machine learning model that helps detect malware.

# Project Steps

Imported necessary libraries such as numpy, pandas, seaborn among others
Imported load_svmlight_file required for structuring sparse dataset
Converted the txt files into csvs respectively and concatenated into one csv file
Created generic feature names since the features that came with the dataset weren't understandable
Checked attribute like shape, missing value, distribution of the dataset 
Ascertained if there were missing values, fortunately there was none
Carried out statistical summary of the data
Removed every features that have entirely zeros
Carried out correlation analysis of the features with respect to the target varible
Introduced ExtraTreeRegressor for Feature Selection and picked the best 10
Converted the target varible to 0 and 1
Ascertained if target variable is balanced or imbalanced
Checked for outliers and scaled the features using RobustScaler
Curated Logistic, Random Forest, XGBoost and AdaBoost Classifers and confusion matrix respectively
Carried out some mild unspervised learning on the dataset


# Insights
Correlation does not imply causation came into play as most features were negatively correlated and the highest correlated value is about 0.2. Hence, no strongly correlated feature. We utilized ExtraTreeRegressor to help select the best 10 features based on their importance and contribution to the dataset. Surprisingly, negatively correlated were part of the best 10 selected

Out of 481 features, 214 had entirely zeros which did not contribute to the target data in anyway. The zero features were completely taken out

Feature 81, 210 and 152 had outliers, as a result we applied RobustScaler to scale document to avoid overfitting by the models

Logistic regression mClassifier did not experience overfitting since the model had 71.6% accuracy on the train set and 71.2% on the test set. However, balanced accuracy is about 51.4% showing that the target variable is imbalanced. Which indicates Logistic regression is not a good model for the dataset. Meanwhile, the model predicts the malware correctly with about 72.7% precision and is able to identify malware at about 96.2%

Random Forest Classifier did experience moderate overfitting since the model had 91.9% accuracy on the train set and 83.1% on the test set. Balanced accuracy is about 77% showing that it is well suited for imbalanced dataset, infact the F1-score corroborated that.  Meanwhile, the model predicts the malware correctly with about 87% precision and is able to identify malware at about 90%.

XGBoost Classifier did experience very mild overfitting since the model had 85% accuracy on the train set and 83.4% on the test set. Balanced accuracy is about 78% showing that it is well suited for imbalanced dataset, infact the F1-score corroborated that.  Meanwhile, the model predicts the malware correctly with about 87% precision and is able to identify malware at about 91%.

AdaBoost model did not experience overfitting since the model had 76% accuracy on the train set and 76% on the test set. Balanced accuracy is about 63% showing that it is well suited for imbalanced dataset, infact the F1-score corroborated that.  Meanwhile, the model predicts the malware correctly with about 78% precision and is able to identify malware at about 92%.

In general, the Random Forest, AdaBoost and XGBoost Classifiers results corroborate the general idea that ensemble methods are very suitable for sparse dataset alongside imbalanced target variables.

Lastly, we ran MaxAbsScaler on the dataset and then ran PCA on it where the screeplot showed that 2 principal components is the best to use. We did that and went ahead to also obtain Silhoutte scores

